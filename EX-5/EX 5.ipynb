{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h6DRNrFRotPR","outputId":"14f5e2d6-23e9-4cfa-8e55-c94d2bfc8ae5"},"outputs":[{"name":"stdout","output_type":"stream","text":["350715\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","words = [w.lower() for w in nltk.corpus.state_union.words() if w.isalpha()]\n","#print(words)\n","#stopwords = nltk.corpus.stopwords.words(\"english\")\n","print(len(words))\n","#print(stopwords)\n","#words = [w for w in words if w.lower() not in stopwords]\n","#print(len(words))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5F_KmJpTotPX","outputId":"a9b044d2-1553-4271-f9a5-fc13263bfdeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('the', 20914), ('of', 13004), ('and', 12828)]\n","  the    of   and \n","20914 13004 12828 \n","None\n"]}],"source":["fd = nltk.FreqDist(words)\n","print(fd.most_common(3))\n","print(fd.tabulate(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1kn8CAHotPX","outputId":"8d4e3d2e-1ce6-446a-d70a-0c47a2cf16fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1079\n","0\n"]}],"source":["print(fd[\"America\"])\n","print(fd[\"america\"])\n","print(fd[\"AMERICA\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I79_PXliotPY","outputId":"ec1fc4d1-10d1-49f9-f173-50931b6e5ca5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Displaying 5 of 1079 matches:\n"," would want us to do . That is what America will do . So much blood has already\n","ay , the entire world is looking to America for enlightened leadership to peace\n","beyond any shadow of a doubt , that America will continue the fight for freedom\n"," to make complete victory certain , America will never become a party to any pl\n","nly in law and in justice . Here in America , we have labored long and hard to \n"]}],"source":["text = nltk.Text(nltk.corpus.state_union.words())\n","text.concordance(\"america\", lines=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cWwm_T7ootPZ","outputId":"1238ce7b-32b8-4812-89ac-4eb247972687"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('the', 20914), ('of', 13004), ('and', 12828)]\n","  the    of   and \n","20914 13004 12828 \n","None\n"]}],"source":["#fd = text.vocab()\n","fd = nltk.FreqDist(words)\n","print(fd.most_common(3))\n","print(fd.tabulate(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYXc7aVUotPZ"},"outputs":[],"source":["finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0VaOhX5otPZ","outputId":"71e616a2-d2b6-4091-f894-2447b3f5e7ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(('the', 'united', 'states'), 327), (('the', 'american', 'people'), 208), (('the', 'state', 'of'), 171), (('to', 'the', 'congress'), 164), (('state', 'of', 'the'), 164)]\n"]}],"source":["t1=finder.ngram_fd.most_common(5)\n","print(t1)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"cSqbk-nQotPa","executionInfo":{"status":"ok","timestamp":1653976139414,"user_tz":-330,"elapsed":1332,"user":{"displayName":"P. Tamil Selvi","userId":"10394445137309315717"}},"outputId":"a1d149d4-06e0-4495-d02d-5ef3634c4327","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"]},{"output_type":"execute_result","data":{"text/plain":["{'compound': -0.6808, 'neg': 0.483, 'neu': 0.517, 'pos': 0.0}"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","sia = SentimentIntensityAnalyzer()\n","#sia.polarity_scores(\"Wow, NLTK is really powerful!\")\n","sia.polarity_scores(\"It is too bad to cut the class\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nk6BwyF0otPb","outputId":"f815a47d-5154-46b5-9186-edf01607ae4f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading twitter_samples: <urlopen error [Errno\n","[nltk_data]     11001] getaddrinfo failed>\n"]}],"source":["import nltk\n","nltk.download('twitter_samples')\n","tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thlytfbIotPc","outputId":"6f64cb6e-2671-4f14-8e58-a115c9a194f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["> False RT @TheAbsoluteLad: Ed Miliband fell off the stage. Just thought you should see —&gt; http//t.co/7IVo8bwf0Q\n","> False #askleanne #Plaid15 Labour leader irresponsible by leaving the door open for another Tory government @LeanneWood @Plaid_Cymru\n","> False @AnnieIsDoomed its not my fault sweedy :(\n","> False RT @DekBannan: Labour may form government, but has @Ed_Miliband blown his chances of being PM, hell yes!! #VoteSNP #SNP #GE2015 #howcanedle…\n","> True RT @GaryLineker: Thought Ed Miliband did well to stay on his feet. Many would have gone down under those circumstances, especially on the b…\n","> False If Labour thought siding with the Tories harmed them then just wait and see what letting them just walk back into government will do\n","> True RT @Nigel_Farage: Thanks for watching #AskNigelFarage! If you want more detail please visit http//t.co/YMvAusaXi8\n","> True RT @WalesForIndy: Did you hear that No Voters?\n","\n","Your Labour leader prefers a Tory Govt rather than a stronger voice for Scotland.\n","\n","Well don…\n","> False I don't think aurora likes SNP\n","> False RT @Bonn1eGreer: \"Ed  slipped on #DavidCameron 's sweat..\"via @benglaze-@Kevin_Maguire\n","#shyster \n","#Tories\n","#GE2015\n","#Milibrand \n","https//t.co/Z…\n"]}],"source":["from random import shuffle\n","\n","def is_positive(tweet):\n","    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n","    return sia.polarity_scores(tweet)[\"compound\"] > 0\n","\n","shuffle(tweets)\n","for tweet in tweets[:10]:\n","    print(\">\", is_positive(tweet), tweet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPd7PTrlotPc","outputId":"660efe8e-77e9-403c-9bbe-19f6492e5c26"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading movie_reviews: <urlopen error [Errno 11001]\n","[nltk_data]     getaddrinfo failed>\n"]}],"source":["import nltk\n","nltk.download('movie_reviews')\n","\n","positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n","negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n","all_review_ids = positive_review_ids + negative_review_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZpCvofrotPd"},"outputs":[],"source":["from statistics import mean\n","\n","def is_positive(review_id):\n","    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n","    text = nltk.corpus.movie_reviews.raw(review_id)\n","    scores = [\n","        sia.polarity_scores(sentence)[\"compound\"]\n","        for sentence in nltk.sent_tokenize(text)\n","    ]\n","    return mean(scores) > 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPTCUWTdotPd","outputId":"7f3d2370-e9b8-482e-b3d5-54ea2049f2db"},"outputs":[{"ename":"NameError","evalue":"name 'shuffle' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-e4a2dda4bf35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_review_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mreview_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_review_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreview_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_review_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'shuffle' is not defined"]}],"source":["shuffle(all_review_ids)\n","correct = 0\n","for review_id in all_review_ids:\n","    if is_positive(review_id):\n","        if review_id in positive_review_ids:\n","            correct += 1\n","        else:\n","            if review_id in negative_review_ids:\n","                correct += 1\n","\n","print(F\"{correct / len(all_review_ids):.2%} correct\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Hn5Ih8ootPd"},"outputs":[],"source":["unwanted = nltk.corpus.stopwords.words(\"english\")\n","unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n","\n","def skip_unwanted(pos_tuple):\n","    word, tag = pos_tuple\n","    if not word.isalpha() or word in unwanted:\n","        return False\n","    if tag.startswith(\"NN\"):\n","        return False\n","    return True\n","\n","positive_words = [word for word, tag in filter(\n","    skip_unwanted,\n","    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",")]\n","negative_words = [word for word, tag in filter(\n","    skip_unwanted,\n","    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",")]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1QPZNN_otPe"},"outputs":[],"source":["positive_fd = nltk.FreqDist(positive_words)\n","negative_fd = nltk.FreqDist(negative_words)\n","\n","common_set = set(positive_fd).intersection(negative_fd)\n","\n","for word in common_set:\n","    del positive_fd[word]\n","    del negative_fd[word]\n","\n","top_100_positive = {word for word, count in positive_fd.most_common(100)}\n","top_100_negative = {word for word, count in negative_fd.most_common(100)}\n","print(top_100_positive)\n","print(top_100_negative)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NmqZ9GGotPe"},"outputs":[],"source":["unwanted = nltk.corpus.stopwords.words(\"english\")\n","unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n","\n","positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n","    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n","    if w.isalpha() and w not in unwanted\n","])\n","negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n","    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n","    if w.isalpha() and w not in unwanted\n","])\n","print(positive_bigram_finder)\n","print(negative_bigram_finder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLQT--vCotPe"},"outputs":[],"source":["def extract_features(text):\n","    features = dict()\n","    wordcount = 0\n","    compound_scores = list()\n","    positive_scores = list()\n","\n","    for sentence in nltk.sent_tokenize(text):\n","        for word in nltk.word_tokenize(sentence):\n","            if word.lower() in top_100_positive:\n","                wordcount += 1\n","        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n","        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n","\n","    # Adding 1 to the final compound score to always have positive numbers\n","    # since some classifiers you'll use later don't work with negative numbers.\n","    features[\"mean_compound\"] = mean(compound_scores) + 1\n","    features[\"mean_positive\"] = mean(positive_scores)\n","    features[\"wordcount\"] = wordcount\n","\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIZ4jk8qotPf"},"outputs":[],"source":["features = [\n","    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n","    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n","]\n","features.extend([\n","    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n","    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQByJccbotPf"},"outputs":[],"source":["print(features)\n","#print(features.extend)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWCWVng2otPf"},"outputs":[],"source":["# Use 1/4 of the set for training\n","train_count = len(features)*3// 4\n","print(len(features),train_count)\n","shuffle(features)\n","classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n","classifier.show_most_informative_features(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IM_kpap3otPf"},"outputs":[],"source":["nltk.classify.accuracy(classifier, features[train_count:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IKEHLEzotPg"},"outputs":[],"source":["from sklearn.naive_bayes import (\n","    BernoulliNB,\n","    #ComplementNB,\n","    MultinomialNB,\n",")\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzIG45gBotPg"},"outputs":[],"source":["classifiers = {\n","    \"BernoulliNB\": BernoulliNB(),\n","    #\"ComplementNB\": ComplementNB(),\n","    \"MultinomialNB\": MultinomialNB(),\n","    \"KNeighborsClassifier\": KNeighborsClassifier(),\n","    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n","    \"RandomForestClassifier\": RandomForestClassifier(),\n","    \"LogisticRegression\": LogisticRegression(),\n","    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n","    \"AdaBoostClassifier\": AdaBoostClassifier(),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5N-6JLUotPg"},"outputs":[],"source":["train_count = len(features) // 2\n","print(train_count)\n","shuffle(features)\n","for name, sklearn_classifier in classifiers.items():\n","    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n","    classifier.train(features[:train_count])\n","    accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n","    print(F\"{accuracy:.2%} - {name}\")"]},{"cell_type":"markdown","metadata":{"id":"Phd5Q1KVotPg"},"source":["# "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"EX 5.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}